"""Implements a metric that tracks a pipeline in which it was calculated and allows for automatic plotting of batch
components on its interactive maps"""

from inspect import signature
from functools import partial

import numpy as np
from batchflow import Pipeline

from .metric import Metric
from ..utils import to_list, get_first_defined


class PipelineMetric(Metric):
    """Define a metric that tracks a pipeline in which it was calculated and allows for automatic plotting of batch
    components on its interactive maps.

    Examples
    --------
    Define a metric, that calculates standard deviation of gather amplitudes:
    >>> class StdMetric(PipelineMetric):
    ...     name = "std"
    ...     min_value = 0
    ...     max_value = None
    ...     is_lower_better = None
    ...     args_to_unpack = "gather"
    ...
    ...     @classmethod
    ...     def calc(cls, gather):
    ...         return gather.data.std()
    Note that the defined `calc` method operates on each batch item independently.

    Calculate the metric for a given dataset:
    >>> survey = Survey(path, header_index="FieldRecord", header_cols=["SourceY", "SourceX", "offset"], name="raw")
    >>> dataset = SeismicDataset(survey)
    >>> pipeline = (dataset
    ...     .pipeline()
    ...     .load(src="raw")
    ...     .calculate_metric(StdMetric, gather="raw", save_to=V("accumulator", mode="a"))
    ... )
    >>> pipeline.run(batch_size=16, n_epochs=1)

    `PipelineMetric` tracks a pipeline in which it was calculated. This allows reconstructing the batch used to compute
    the metric and plot its components on click on the interactive metric map:
    >>> std_map = pipeline.v("accumulator").construct_map()
    >>> std_map.plot(interactive=True, plot_component="raw")

    If a `pipeline` argument is passed, it will be used instead of the one used to calculate the metric:
    >>> plot_pipeline = Pipeline().load(src="raw").sort(src="raw", dst="sorted", by="offset")
    >>> std_map.plot(interactive=True, pipeline=plot_pipeline, plot_component="sorted")

    If several components are passed, a multiview plot is created:
    >>> std_map.plot(interactive=True, pipeline=plot_pipeline, plot_component=["raw", "sorted"])

    By default, the batch to execute the pipeline for is generated by the dataset index, corresponding to click
    coordinates which allows running the same pipeline used for metric computation. Click coordinates can be used
    directly to generate the batch, but in this case the default pipeline will simply load the requested component by
    the survey name:
    >>> std_map.plot(interactive=True, batch_src="coords", plot_component="raw")

    However, a `pipeline` can be specified as well as in the index case:
    >>> std_map.plot(interactive=True, batch_src="coords", pipeline=plot_pipeline, plot_component=["raw", "sorted"])

    A `PipelineMetric` allows for defining default views. Each of them must be a `classmethod` decorated with one of
    @pass_coords, @pass_batch or @pass_calc_args decorators that specify which additional arguments will be passed to
    the view along with the axes to plot on. Each of the views must be listed in the `views` class attribute. The
    following class extends the `StdMetric` class with two views: one plotting the gather used to calculate the metric
    itself and the other plotting the same gather sorted by offset.
    >>> class PlotStdMetric(StdMetric):
    ...     views = ("plot", "plot_sorted")
    ...
    ...     @pass_calc_args
    ...     def plot(cls, gather, ax, **kwargs):
    ...         return gather.plot(ax=ax, **kwargs)
    ...
    ...     @pass_calc_args
    ...     def plot_sorted(cls, gather, ax, **kwargs):
    ...         return gather.sort(by="offset").plot(ax=ax, **kwargs)

    In this case an interactive plot of the map may be constructed without any extra arguments:
    >>> pipeline = (dataset
    ...     .pipeline()
    ...     .load(src="raw")
    ...     .calculate_metric(PlotStdMetric, gather="raw", save_to=V("accumulator", mode="a"))
    ... )
    >>> pipeline.run(batch_size=16, n_epochs=1)
    >>> std_map = pipeline.v("accumulator").construct_map()
    >>> std_map.plot(interactive=True)

    Parameters
    ----------
    pipeline : Pipeline
        A pipeline used to calculate the metric.
    calculate_metric_index : int
        An ordinal number of the `calculate_metric` action produced the current metric.
    coords_cols : array-like with 2 elements, optional
        Names of the dataset headers used to extract X and Y coordinates from.
    coords_to_pos : dict, optional
        A mapping from spatial coordinates to the ordinal numbers of indices in the dataset for which the pipeline was
        executed.
    kwargs : misc, optional
        Additional keyword arguments to :func:`~Metric.__init__`.

    Attributes
    ----------
    args_to_unpack : str or list of str or "all"
        `calc` method arguments to unpack. Unpacking is performed in the following way:
        * If argument value is `str`, it is treated as a batch component name to get the actual argument from,
        * If argument value is an array-like whose length matches the length of the batch, its elements are passed to
          `calc` methods for the corresponding batch items.
        * Otherwise the argument value is passed to `calc` methods for all batch items.
        If "all", tries to unpack all the arguments.
    views : str or iterable of str
        Default views of the metric to display on click on a metric map in interactive mode.
    dataset : SeismicDataset
        The dataset for which the metric was calculated.
    coords_dataset : SeismicDataset or None
        The `dataset` reindexed by `coords_cols` if they were given.
    plot_pipeline : Pipeline
        The `pipeline` up to the `calculate_metric` method.
    coords_cols : array-like with 2 elements, optional
        Names of the dataset headers used to extract X and Y coordinates from.
    coords_to_pos : dict or None
        A mapping from spatial coordinates to the ordinal numbers of indices in the dataset for which the pipeline was
        executed.
    """
    args_to_unpack = None

    def __init__(self, name=None):
        super().__init__(name=name)

        # Attributes set after context binding
        self.dataset = None
        self.plot_pipeline = None
        self.calculate_metric_args = None
        self.calculate_metric_kwargs = None

    def __call__(self, value):
        """Return an already calculated metric. May be overridden in child classes."""
        return value

    def bind(self, metric_map, pipeline, calculate_metric_index):
        _ = metric_map
        self.dataset = pipeline.dataset

        # Slice the pipeline in which the metric was calculated up to its calculate_metric call
        # pylint: disable=protected-access
        calculate_metric_indices = [i for i, action in enumerate(pipeline._actions)
                                      if action["name"] == "calculate_metric"]
        calculate_metric_action_index = calculate_metric_indices[calculate_metric_index]
        actions = pipeline._actions[:calculate_metric_action_index]
        self.plot_pipeline = Pipeline(pipeline=pipeline, actions=actions)

        # Get args and kwargs of the calculate_metric call with possible named expressions in them
        self.calculate_metric_args = pipeline._actions[calculate_metric_action_index]["args"]
        self.calculate_metric_kwargs = pipeline._actions[calculate_metric_action_index]["kwargs"]
        # pylint: enable=protected-access
        return self

    def get_calc_signature(self):
        return signature(self.__call__)

    def unpack_calc_args(self, batch, *args, **kwargs):
        """Unpack arguments for metric calculation depending on the `args_to_unpack` class attribute and return them
        with the first unpacked `calc` argument. If `args_to_unpack` equals "all", tries to unpack all the passed
        arguments.

        Unpacking is performed in the following way:
        * If argument value is `str`, it is treated as a batch component name to get the actual argument from,
        * If argument value is an array-like whose length matches the length of the batch, its elements are passed to
          `calc` methods for the corresponding batch items.
        * Otherwise the argument value is passed to `calc` methods for all batch items.
        """
        sign = self.get_calc_signature()
        bound_args = sign.bind(*args, **kwargs)

        # Determine arguments to unpack
        if self.args_to_unpack is None:
            args_to_unpack = set()
        elif self.args_to_unpack == "all":
            args_to_unpack = {name for name, param in sign.parameters.items()
                                   if param.kind not in {param.VAR_POSITIONAL, param.VAR_KEYWORD}}
        else:
            args_to_unpack = set(to_list(self.args_to_unpack))

        # Convert the value of each argument to an array-like matching the length of the batch
        packed_args = {}
        for arg, val in bound_args.arguments.items():
            if arg in args_to_unpack:
                if isinstance(val, str):
                    packed_args[arg] = getattr(batch, val)
                elif isinstance(val, (tuple, list, np.ndarray)) and len(val) == len(batch):
                    packed_args[arg] = val
                else:
                    packed_args[arg] = [val] * len(batch)
            else:
                packed_args[arg] = [val] * len(batch)

        # Extract the values of the first calc argument to use them as a default source for coordinates calculation
        first_arg = packed_args[list(sign.parameters.keys())[0]]

        # Convert packed args dict to a list of calc args and kwargs for each of the batch items
        unpacked_args = []
        for values in zip(*packed_args.values()):
            bound_args.arguments = dict(zip(packed_args.keys(), values))
            unpacked_args.append((bound_args.args, bound_args.kwargs))
        return unpacked_args, first_arg

    def eval_calc_args(self, batch):
        """Evaluate named expressions in arguments passed to `calc` method and unpack arguments for the first batch
        item."""
        sign = signature(batch.calculate_metric)
        bound_args = sign.bind(*self.calculate_metric_args, **self.calculate_metric_kwargs)
        bound_args.apply_defaults()
        # pylint: disable=protected-access
        calc_args = self.plot_pipeline._eval_expr(bound_args.arguments["args"], batch=batch)
        calc_kwargs = self.plot_pipeline._eval_expr(bound_args.arguments["kwargs"], batch=batch)
        # pylint: enable=protected-access
        args, _ = self.unpack_calc_args(batch, *calc_args, **calc_kwargs)
        return args[0]

    def make_batch(self, index):
        """Construct a batch for given spatial `coords` and execute the `pipeline` for it. The batch can be generated
        either directly from coords if `batch_src` is "coords" or from the corresponding index if `batch_src` is
        "index"."""
        subset_index = [[index[1:]] if i == index[0] else [] for i in range(self.dataset.n_parts)]
        batch = self.dataset.create_subset(subset_index).next_batch(1, shuffle=False)
        return self.plot_pipeline.execute_for(batch)

    def plot_component(self, ax, coords, index, plot_component, **kwargs):
        """Construct a batch by click coordinates and plot its component."""
        _ = coords
        batch = self.make_batch(index)
        item = getattr(batch, plot_component)[0]
        item.plot(ax=ax, **kwargs)

    def plot_view(self, ax, coords, index, view_fn, **kwargs):
        """Plot a given metric view. Pass extra arguments depending on `@pass_*` decorator."""
        _ = coords
        batch = self.make_batch(index)
        calc_args, calc_kwargs = self.eval_calc_args(batch)
        return view_fn(*calc_args, ax=ax, **calc_kwargs, **kwargs)

    def get_views(self, plot_component=None, **kwargs):
        """Get metric views by parameters passed to interactive metric map plotter. If `plot_component` is given,
        batch components are displayed. Otherwise defined metric views are shown."""
        if plot_component is not None:
            views = [partial(self.plot_component, plot_component=component) for component in to_list(plot_component)]
            return views, kwargs

        view_fns = [getattr(self, view) for view in to_list(self.views)]
        return [partial(self.plot_view, view_fn=view_fn) for view_fn in view_fns], kwargs


class FunctionalMetric(PipelineMetric):
    args_to_unpack = "all"

    def __init__(self, func, name=None):
        if not callable(func):
            raise ValueError("func must be callable")
        self.func = func
        super().__init__(name=name)

        # Attributes set after context binding
        self.dataset = None
        self.plot_pipeline = None
        self.calculate_metric_args = None
        self.calculate_metric_kwargs = None

    def __repr__(self):
        """String representation of the metric."""
        return f"{type(self).__name__}(func='{self.func.__name__}', name='{self.name}')"

    def __call__(self, *args, **kwargs):
        return self.func(*args, **kwargs)

    def get_calc_signature(self):
        return signature(self.func)


def define_pipeline_metric(metric, metric_name=None):
    """Define a new `PipelineMetric` from a `callable` or another `PipelineMetric`. In the first case, the `callable`
    defines `calc` method of the metric. In the latter case only the new metric name is being set."""
    if isinstance(metric, PipelineMetric):  # Instantiated metric
        return metric.set_name(metric_name)
    if isinstance(metric, type) and issubclass(metric, PipelineMetric):  # Non-instantiated metric
        return metric(name=metric_name)
    if callable(metric):
        return FunctionalMetric(func=metric, name=metric_name)
    raise ValueError("metric must be either an instance of PipelineMetric or its subclass or a callable")
